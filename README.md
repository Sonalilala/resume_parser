# resume_parser

So for this usecase I have tried  few approaches. And one approach because of time constraints, was not able to finish but I would like to talk about it a bit. Through this assignment I have concentrated on different approaches rather than the accuracy so that I can showcase my thought process. I have not  processed all the directory  as I just wanted to show the working part.

1. So my first approach was to find if there is some library, algorithm or any transfer learning tool is available or not so that we can develop this usecase in limited time.
I found this package which parses the resume and extract useful implementation. The implementation is there in file resume_parser_package.ipynb and how we can extract summary from resume

2.,3  My second and third approach was to create a knowledge base using the requirements (JD files) which will have information of role and skills and experience we can extract using regular expression. So in one approach ('extract_resume.py') I have just added a list of skills and job roles. It can be enhanced by adding more information by BA. In other approach('build_knowledge_base.py') I am extracting skills and job role using regular expressions. The problem with this approach that it will only work if the requirement is in a specific format. This is the reason I was able to only 3 JDs information. These are simple approaches but can produce really good results if enhanced.

4. The fourth approach was using Ner. In this ('resume_parser.ipynb') I have created custom ner. Again this is just to show the capability that's why I have not worked with all the resumes. Also in ner the data has to be annotated. So I have manually annotated two job requirements file and trained the custom spacy ner model. I  have worked with only  .docx file as my concentration was on ner rather than different format of files. I have created three classes in the ner - 'ROLE',"SKILL',"SOFTSKILL'.  I am summarizing all the .docx file in ui folder(taken example as the spacy module is trained using ui jd). For evaluation once we have important metrics(keywords, phrases) from job requirements and resumes, we can easily use scores by counting how many keywords are matched and then rank resume.Or we can use document similarity matching by using tf idf or we can use semantic matching using glove, bert etc. Here I have used spacy module to measure similarity between jd file and resume and ranked them.

5. The last approach which I was not able to finish due time constraint as I have to manually prepare dataset. This approach uses transfer learning. The idea behind this was to use any text  to text transformer language model(t5, Bart etc) and pass dataset as resume and summary. As we are fine tuning the model , we can implement few shot learning techniques, and with few hundred samples a model can be build. 
